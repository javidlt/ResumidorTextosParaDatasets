{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Instalar librerías necesarias"
      ],
      "metadata": {
        "id": "GM8AT72CpsCU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wi24JlpAo2k8",
        "outputId": "81f8d2ce-3a3b-41a8-8159-9642216780b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/dist-packages (from pandas) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: validators in /usr/local/lib/python3.9/dist-packages (0.20.0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.9/dist-packages (from validators) (4.4.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: newspaper3k in /usr/local/lib/python3.9/dist-packages (0.2.8)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (2.8.2)\n",
            "Requirement already satisfied: cssselect>=0.9.2 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: feedfinder2>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (0.0.4)\n",
            "Requirement already satisfied: tldextract>=2.0.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (3.4.1)\n",
            "Requirement already satisfied: jieba3k>=0.35.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (0.35.1)\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (3.8.1)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (4.9.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (4.11.2)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (2.27.1)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (6.0)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (8.4.0)\n",
            "Requirement already satisfied: tinysegmenter==0.3 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (0.3)\n",
            "Requirement already satisfied: feedparser>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from newspaper3k) (6.0.10)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4>=4.4.1->newspaper3k) (2.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from feedfinder2>=0.0.4->newspaper3k) (1.16.0)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.9/dist-packages (from feedparser>=5.2.1->newspaper3k) (1.0.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (1.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (4.65.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.2.1->newspaper3k) (8.1.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.10.0->newspaper3k) (1.26.15)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.9/dist-packages (from tldextract>=2.0.1->newspaper3k) (3.12.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.9/dist-packages (from tldextract>=2.0.1->newspaper3k) (1.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: google in /usr/local/lib/python3.9/dist-packages (2.0.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from google) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->google) (2.4.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.7.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: visualise_spacy_tree in /usr/local/lib/python3.9/dist-packages (0.0.6)\n",
            "Requirement already satisfied: pydot==1.4.1 in /usr/local/lib/python3.9/dist-packages (from visualise_spacy_tree) (1.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.1.4 in /usr/local/lib/python3.9/dist-packages (from pydot==1.4.1->visualise_spacy_tree) (3.0.9)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.9/dist-packages (1.3.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install validators\n",
        "!pip install newspaper3k\n",
        "!pip install google\n",
        "!pip install spacy\n",
        "!pip install visualise_spacy_tree\n",
        "!pip install unidecode"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar librerías "
      ],
      "metadata": {
        "id": "Ijbbnf9Xpz4z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests \n",
        "import re\n",
        "import validators\n",
        "from googlesearch import search \n",
        "from newspaper import Article\n",
        "\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from string import punctuation\n",
        "from heapq import nlargest\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "\n",
        "from spacy import displacy \n",
        "import visualise_spacy_tree\n",
        "from IPython.display import Image, display\n",
        "\n",
        "# load english language model\n",
        "nlp = spacy.load('en_core_web_sm',disable=['ner','textcat'])\n",
        "\n",
        "from unidecode import unidecode"
      ],
      "metadata": {
        "id": "UmWDnubEp5sz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Traer drive para dataset"
      ],
      "metadata": {
        "id": "zqaSvSmMqMyo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0izHBYopqQTI",
        "outputId": "288f95af-c488-45a0-b806-f802aad53832"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset de dónde tomar links"
      ],
      "metadata": {
        "id": "6bJUJaKf4r5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Agregar dirección del archivo en pd.read_excel('/content/drive/{aqui}')\n",
        "dfWithTextsToSummarize = pd.read_excel('/content/drive/')"
      ],
      "metadata": {
        "id": "N7ljJGty4AaY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Función para resumir textos"
      ],
      "metadata": {
        "id": "G9DYqLANrsJB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# resumir texto (texto, qué tan largo queremos que sea el resumen generado)\n",
        "def summarizeText(text, per):\n",
        "  try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "    doc= nlp(text)\n",
        "    tokens=[token.text for token in doc]\n",
        "    word_frequencies={}\n",
        "    for word in doc:\n",
        "        if word.text.lower() not in list(STOP_WORDS):\n",
        "            if word.text.lower() not in punctuation:\n",
        "                if word.text not in word_frequencies.keys():\n",
        "                    word_frequencies[word.text] = 1\n",
        "                else:\n",
        "                    word_frequencies[word.text] += 1\n",
        "    max_frequency=max(word_frequencies.values())\n",
        "    for word in word_frequencies.keys():\n",
        "        word_frequencies[word]=word_frequencies[word]/max_frequency\n",
        "    sentence_tokens= [sent for sent in doc.sents]\n",
        "    sentence_scores = {}\n",
        "    for sent in sentence_tokens:\n",
        "        for word in sent:\n",
        "            if word.text.lower() in word_frequencies.keys():\n",
        "                if sent not in sentence_scores.keys():\n",
        "                    sentence_scores[sent]=word_frequencies[word.text.lower()]\n",
        "                else:\n",
        "                    sentence_scores[sent]+=word_frequencies[word.text.lower()]\n",
        "    select_length=int(len(sentence_tokens)*per)\n",
        "    summary=nlargest(select_length, sentence_scores,key=sentence_scores.get)\n",
        "    final_summary=[word.text for word in summary]\n",
        "    summary=''.join(final_summary)\n",
        "    return summary\n",
        "  except:\n",
        "    return \"no es un articulo\""
      ],
      "metadata": {
        "id": "Oa5pWMFZry3q"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCIÓN QUE TRAE TEXTO DE LINK"
      ],
      "metadata": {
        "id": "hq7cN7Iu7tJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# traer contenido de un html\n",
        "def bringTextFromLink(url):\n",
        "  try: \n",
        "    article = Article(url)\n",
        "    article.download()\n",
        "    article.parse()\n",
        "\n",
        "    return article.text\n",
        "  except: \n",
        "    return \"0\""
      ],
      "metadata": {
        "id": "Hlg-xepu7sX-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FUNCIONES PARA EL PROMEDIO DE PALABRAS POR RESUMEN Y SU DESVIACIÓN ESTANDAR"
      ],
      "metadata": {
        "id": "yEF35Jr9BmiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def promPalabrasPorTexto(listaDeTextos):\n",
        "    cantidadTextos = len(listaDeTextos)\n",
        "    sumaTotalPalabras = 0\n",
        "    for text in listaDeTextos:\n",
        "      textoLimpio = text.replace(\"  \", \" \")\n",
        "      separarTextoEnListaDePalabras = textoLimpio.split(\" \")\n",
        "      cantidadPalabras = len(separarTextoEnListaDePalabras)\n",
        "      sumaTotalPalabras += cantidadPalabras\n",
        "    \n",
        "    promedio = sumaTotalPalabras/cantidadTextos\n",
        "    return promedio\n",
        "\n",
        "def desvEstandar(prom, listaDeTextos):\n",
        "  cantidadTextos = len(listaDeTextos)\n",
        "  sumatoriaNumerador = 0\n",
        "  for text in listaDeTextos:\n",
        "    textoLimpio = text.replace(\"  \", \" \")\n",
        "    separarTextoEnListaDePalabras = textoLimpio.split(\" \")\n",
        "    cantidadPalabras = len(separarTextoEnListaDePalabras)\n",
        "    restaYCuadrado = (cantidadPalabras-prom)**2\n",
        "    sumatoriaNumerador += restaYCuadrado\n",
        "  \n",
        "  desvEst = pow((sumatoriaNumerador/cantidadTextos), (1/2))\n",
        "  return desvEst\n"
      ],
      "metadata": {
        "id": "yLGxzvWlBvkJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CASO 1: CUANDO SOLO SE TIENEN LAS REFERENCIAS"
      ],
      "metadata": {
        "id": "yyAeik225CEN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear columna en dataset para agregar los resumenes \n",
        "nombreDeLaColumnaParaLosResumenes = \"\"\n",
        "dfWithTextsToSummarize[nombreDeLaColumnaParaLosResumenes] = \"\"\n",
        "\n",
        "# Agregar en variable columna Referencias la columna en dónde están almacenadas la referencia o las referencias\n",
        "columnaReferencias = \"\"\n",
        "# Agregar el caracter que separa las referencias\n",
        "caracterQueSeparaLasReferencias = \"\"\n",
        "\n",
        "# Porcentaje al que se desea reducir el texto Ej. .20 -> Rango del 0 al 1\n",
        "porcenatajeAReducirTextos = .20\n",
        "\n",
        "# El siguiente for itera sobre cada caso del dataset\n",
        "for index, row in dfWithTextsToSummarize.iterrows():\n",
        "  # Cambiar nombre de la columna en dónde esta la referencia o están las referencias \n",
        "  referencias = str(row[columnaReferencias])\n",
        "  # la siguiente linea separará las referencias según el caracter que se haya usado para separar los links\n",
        "  listaReferencias = referencias.split(caracterQueSeparaLasReferencias)\n",
        "  \n",
        "  listaResumenesPorCaso = []\n",
        "  # El siguiente for itera sobre cada referencia para obtener su texto \n",
        "  for ref in listaReferencias:\n",
        "    textoLimpioDeLaReferencia = bringTextFromLink(ref)\n",
        "    resumen = summarizeText(textoLimpioDeLaReferencia, porcenatajeAReducirTextos)\n",
        "    if resumen != \"0\":\n",
        "      listaResumenesPorCaso.append(resumen)\n",
        "  \n",
        "  # La siguiente linea concatena la lista de resumenes con el caracter que se introduzca en la variable \"caracterSeparaResumenes\"\n",
        "  caracterSeparaResumenes = \"\"\n",
        "  resumenesConcatenados = str(f\" {caracterSeparaResumenes} \").join(listaResumenesPorCaso)\n",
        "\n",
        "  # Agregar resumen concatenado al caso en la columna correspondiente\n",
        "  dfWithTextsToSummarize.at[index, nombreDeLaColumnaParaLosResumenes] = resumenesConcatenados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLpzOyej3VaP",
        "outputId": "070bcdfb-9ba7-4973-fdf9-1c7c69d9a309"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Building prefix dict from /usr/local/lib/python3.9/dist-packages/jieba/dict.txt ...\n",
            "DEBUG:jieba:Building prefix dict from /usr/local/lib/python3.9/dist-packages/jieba/dict.txt ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.4495165348052979 seconds.\n",
            "DEBUG:jieba:Loading model cost 1.4495165348052979 seconds.\n",
            "Prefix dict has been built succesfully.\n",
            "DEBUG:jieba:Prefix dict has been built succesfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CASO 2: CUANDO YA SE TIENE EL TEXTO POR CASO QUE SE DESA RESUMIR"
      ],
      "metadata": {
        "id": "8y_5bGgR_7K-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear columna en dataset para agregar los resumenes \n",
        "nombreDeLaColumnaParaLosResumenes = \"\"\n",
        "dfWithTextsToSummarize[nombreDeLaColumnaParaLosResumenes] = \"\"\n",
        "\n",
        "# Definir nombre de la columna en dónde se encuentran los textos que se desean resumir\n",
        "nombreColumnaTexto = \"\"\n",
        "\n",
        "# Porcentaje al que se desea reducir el texto Ej. .20 -> Rango del 0 al 1\n",
        "porcenatajeAReducirTextos = .20\n",
        "\n",
        "# El siguiente for itera sobre cada caso del dataset\n",
        "for index, row in dfWithTextsToSummarize.iterrows():\n",
        "  texto = str(row[nombreColumnaTexto])\n",
        "  resumen = summarizeText(texto, porcenatajeAReducirTextos)\n",
        "    \n",
        "  # Agregar resumen al caso en la columna correspondiente\n",
        "  dfWithTextsToSummarize.at[index, nombreDeLaColumnaParaLosResumenes] = resumen"
      ],
      "metadata": {
        "id": "8lXnHFX6AD3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfWithTextsToSummarize.head()"
      ],
      "metadata": {
        "id": "nDeOaUGcKgD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "VISUALIZAR DATASET UNA VEZ CON RESUMENES"
      ],
      "metadata": {
        "id": "Iu3SzdFmAsdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATOS IMPORTANTES SOBRE LOS RESUMENES"
      ],
      "metadata": {
        "id": "lgRNrBkiA_X8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columnaConResumenes = list(dfWithTextsToSummarize[nombreDeLaColumnaParaLosResumenes])\n",
        "promedio = promPalabrasPorTexto(columnaConResumenes)\n",
        "desviacionEstandar = desvEstandar(promedio, columnaConResumenes)\n",
        "\n",
        "print(f\"Promedio de palabras por resumen: {promedio}\")\n",
        "print(f\"Desviación estándar: {desviacionEstandar}\")"
      ],
      "metadata": {
        "id": "QdHJ-tN8BCRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exportar nuevo dataset con resumenes"
      ],
      "metadata": {
        "id": "aV1ZuUMR7A8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# En la siguiente variable asignar el nombre que se quiere que tenga el archivo\n",
        "nombreArchivo = \"EjemploConTextosResumidos\"\n",
        "dfWithTextsToSummarize.to_excel(f'{nombreArchivo}.xlsx')"
      ],
      "metadata": {
        "id": "8OMb_Kes4Lqf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}